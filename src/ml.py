import joblib
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing


# load models
model = joblib.load("../saved_models/random_forest.pkl")
le = joblib.load("../saved_models/le.bin")
# scaler = joblib.load("../saved_models/std_scaler.bin")

# le = joblib.load("../saved_models/le.pkl")

# scale data
# scaler = StandardScaler()

# encode categorical features

index_to_label = {0:'Bening (Good)', 1:'Malicious (Bad)'}
def make_prediction(search):
    # search = df.drop(['version', 'filename'], axis=1)

    search['header'] = le.transform(search['header'])

    # scaled_search = scaler.transform(search)

    pred = model.predict(search)
    # pred = model.predict(scaled_search)

    return index_to_label[pred.item()]